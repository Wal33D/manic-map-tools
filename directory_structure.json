{".env":{"content":"MMT_CATALOG_DIR=C://Users//Aquataze//Desktop//discordChannelBot//downloads MMT_CLEANME_DIR=C://Users//Aquataze//Desktop//discordChannelBot//cleanme MMT_MAPDATA_DIR=C://Users//Aquataze//Desktop//discordChannelBot//downloads"},".gitignore":{"content":"dist .vscode node_modules"},"fileParser":{"mapFileParser.ts":{"content":"import fs from \"fs\"; import iconv from \"iconv-lite\"; import chardet from \"chardet\"; import { ParsedMapData } from \"./types\"; import { countResources, getSizeCategory } from \"./utils\"; /** * Parses map data from a file to extract detailed game map information. * This module reads a map file and parses its contents into a structured format. * Each map file should contain details about rows, columns, and resource distributions * across different sections like tiles, height, ore, and crystals. * * @module parseMapDataFromFile * * Parameters in ParsedMapData: * - rowcount: number of rows in the map * - colcount: number of columns in the map * - size: total number of tiles (rowcount * colcount) * - longestDimension: longer dimension between rowcount and colcount * - shortestDimension: shorter dimension between rowcount and colcount * - orientation: 'x' for horizontal, 'y' for vertical orientation * - maxElevation: highest elevation in the map * - minElevation: lowest elevation in the map * - averageElevation: average elevation across the map * - elevationRange: difference between max and min elevation * - oreCount: total quantity of ore across the map * - crystalCount: total quantity of crystals across the map * - biome: type of biome the map represents * - creator: creator of the map * - levelname: name of the level * - tilesArray: array of tile IDs * - heightArray: array of elevation values * - oreArray: array of ore quantities per tile * - crystalArray: array of crystal quantities per tile */ export function parseMapDataFromFile({ filePath, }: { filePath: string; }): Promise<ParsedMapData> { return new Promise((resolve, reject) => { // Detect the file encoding const encoding = chardet.detectFileSync(filePath) || \"utf8\"; console.log(`Detected file encoding: ${encoding}`); fs.readFile(filePath, (err, data) => { if (err) { console.error(\"Failed to read file\", err); reject(err); return; } // Decode the buffer using the detected encoding const levelFileData = iconv.decode(data, encoding); const parsedData: ParsedMapData = { size: 0, rowcount: 0, colcount: 0, longestDimension: 0, shortestDimension: 0, axisCount: 0, maxElevation: 0, minElevation: Number.MAX_SAFE_INTEGER, averageElevation: 0, elevationRange: 0, oreCount: 0, crystalCount: 0, isSquare: false, biome: \"\", creator: \"\", levelname: \"\", sizeCategory: \"\", tilesArray: [], heightArray: [], oreArray: [], crystalArray: [], }; const lines = levelFileData .split(\"\\n\") .map((line) => line.trim()) .filter((line) => line.length > 0); let currentKey = \"\"; let resourceKey = \"\"; lines.forEach((line) => { if (line.endsWith(\"{\")) { currentKey = line.replace(\"{\", \"\").trim(); } else if (line.startsWith(\"}\")) { currentKey = \"\"; resourceKey = \"\"; } else if (currentKey === \"info\") { const keyValue = line.split(\":\"); const key = keyValue[0].trim(); const value = keyValue[1].trim(); if (key === \"rowcount\" || key === \"colcount\") { parsedData[key] = parseInt(value, 10); } else if ( key === \"biome\" || key === \"creator\" || key === \"levelname\" ) { parsedData[key] = value; } } else if (currentKey === \"resources\") { if (line.includes(\":\")) { resourceKey = line.split(\":\")[0].trim(); } else if (resourceKey) { const numbers = line .split(\",\") .filter((n) => n.trim() !== \"\") .map((n) => parseInt(n, 10)) .filter((n) => !isNaN(n)); if (resourceKey === \"crystals\") { parsedData.crystalArray = parsedData.crystalArray.concat(numbers); } else if (resourceKey === \"ore\") { parsedData.oreArray = parsedData.oreArray.concat(numbers); } } } else if (currentKey === \"tiles\" || currentKey === \"height\") { const numbers = line .split(\",\") .filter((n) => n.trim() !== \"\") .map((n) => parseInt(n, 10)) .filter((n) => !isNaN(n)); if (currentKey === \"tiles\") { parsedData.tilesArray = parsedData.tilesArray.concat(numbers); } else if (currentKey === \"height\") { parsedData.heightArray = parsedData.heightArray.concat(numbers); } } }); parsedData.oreCount = countResources(parsedData.oreArray); parsedData.crystalCount = countResources(parsedData.crystalArray); if (parsedData.heightArray.length > 0) { parsedData.maxElevation = Math.max(...parsedData.heightArray); parsedData.minElevation = Math.min(...parsedData.heightArray); parsedData.averageElevation = parsedData.heightArray.reduce((acc, val) => acc + val, 0) / parsedData.heightArray.length; parsedData.elevationRange = parsedData.maxElevation - parsedData.minElevation; } parsedData.size = parsedData.rowcount * parsedData.colcount; parsedData.sizeCategory = getSizeCategory(parsedData.size); parsedData.longestDimension = Math.max( parsedData.rowcount, parsedData.colcount ); parsedData.shortestDimension = Math.min( parsedData.rowcount, parsedData.colcount ); parsedData.axisCount = parsedData.rowcount < parsedData.colcount ? parsedData.rowcount : parsedData.colcount; parsedData.isSquare = parsedData.rowcount === parsedData.colcount; resolve(parsedData); }); }); }"},"types.ts":{"content":"export interface ParsedMapData { rowcount: number; colcount: number; size: number; longestDimension: number; shortestDimension: number; axisCount: number; maxElevation: number; minElevation: number; averageElevation: number; elevationRange: number; oreCount: number; crystalCount: number; isSquare: boolean; biome: string; creator: string; levelname: string; sizeCategory: string; tilesArray: number[]; heightArray: number[]; oreArray: number[]; crystalArray: number[]; }"},"utils.ts":{"content":"export function countResources(resourceArray: any[]) { return resourceArray.flat().reduce((count: number, value: number) => { if (value > 0) { return count + value; } return count; }, 0); } export function getSizeCategory(size: number) { const averageSize = 2808.509; const smallThreshold = averageSize * 0.66; const largeThreshold = averageSize * 1.5; if (size < smallThreshold) return \"small\"; if (size > largeThreshold) return \"large\"; return \"medium\"; }"}},"index.ts":{"content":"import * as dotenv from \"dotenv\"; dotenv.config(); async function init() { console.log(\"========== Manic Miners Tools Overview ==========\\n\"); console.log(\"Project Name: Manic Miners Tools\"); console.log(\"Version: 1.0.0\"); console.log(\"Author: Waleed Judah\"); console.log(\"License: MIT\"); console.log(\"\\n\"); console.log(\"Scripts:\"); console.log(\" clean - Removes the dist directory\"); console.log(\" build - Compiles TypeScript files\"); console.log(\" copy-assets - Copies assets to the dist directory\"); console.log(\" prep - Cleans, builds, and copies assets\"); console.log(\" cleanMapFiles - Cleans map files in the specified directory\"); console.log(\" generateMapPNG - Generates PNG images from map files\"); console.log(\" mapIntegrityCheck - Checks the integrity of map tiles\"); console.log(\" determineAVGMapSize - Calculates average map sizes\"); console.log(\" logMapDataStats - Logs statistics of map data\"); console.log(\" minify - Minifies the project directory\\n\"); console.log(\"Environment Variables:\"); console.log(` MMT_CATALOG_DIR: ${process.env.MMT_CATALOG_DIR}`); console.log(` MMT_CLEANME_DIR: ${process.env.MMT_CLEANME_DIR}`); console.log(` MMT_MAPDATA_DIR: ${process.env.MMT_MAPDATA_DIR}\\n`); console.log(\"Ignored Directories and Files:\"); console.log(\" node_modules\"); console.log(\" .vscode\"); console.log(\" package-lock.json\\n\"); console.log(\"Main Directories and Files:\"); console.log(\" .env - Environment variables configuration file\"); console.log(\" fileParser/ - Contains scripts for parsing map files\"); console.log(\" scripts/ - Contains various scripts for different tasks\"); console.log(\" src/ - Source files for the project\"); console.log(\" package.json - Project metadata and dependencies\\n\"); console.log(\"====================================================\\n\"); console.log( \"To get started, you can run any of the scripts listed above using npm.\" ); console.log( \"For example, to clean the map files, use: npm run cleanMapFiles\\n\" ); } init().catch((err) => console.error(\"[ERROR] Error initializing project overview:\", err) );"},"package.json":{"content":"{ \"name\": \"manic-map-tools\", \"version\": \"1.0.0\", \"main\": \"index.js\", \"scripts\": { \"clean\": \"rimraf dist\", \"build\": \"tsc\", \"copy-assets\": \"copyfiles -u 1 ./assets/**/* ./dist\", \"prep\": \"npm run clean && npm run build && npm run copy-assets\", \"cleanMapFiles\": \"npm run prep && node dist/scripts/cleanMapFile.js\", \"generateMapPNG\": \"npm run prep && node dist/scripts/generatePNG.js\", \"mapIntegrityCheck\": \"npm run prep && node dist/scripts/mapIntegrityCheck.js\", \"determineAVGMapSize\": \"npm run prep && node dist/scripts/averageMapSize.js\", \"logMapDataStats\": \"npm run prep && node dist/scripts/logMapDataStats.js\", \"minify\": \"npm run prep && node dist/scripts/minifyProject.js\", \"start\": \"ts-node index.ts\" }, \"author\": \"Waleed Judah\", \"license\": \"MIT\", \"description\": \"A comprehensive toolset for processing, analyzing, and visualizing map data for Manic Miners.\", \"dependencies\": { \"canvas\": \"^2.11.2\", \"chardet\": \"^2.0.0\", \"dotenv\": \"^16.4.5\" }, \"devDependencies\": { \"@types/chardet\": \"^0.8.3\", \"@types/dotenv\": \"^8.2.0\", \"@types/node\": \"^20.12.12\", \"copyfiles\": \"^2.4.1\" } }"},"scripts":{"averageMapSize.ts":{"content":"import * as fs from \"fs/promises\"; import * as path from \"path\"; import * as os from \"os\"; import * as dotenv from \"dotenv\"; import * as readline from \"readline\"; dotenv.config(); const rl = readline.createInterface({ input: process.stdin, output: process.stdout, }); async function calculateMapSizeStats(baseDir: string): Promise<any> { let totalSize = 0; let fileCount = 0; let failedCount = 0; let minSize = Infinity; let maxSize = -Infinity; let failedFiles: string[] = []; let emptyDatDirectories: string[] = []; let directoriesChecked = 0; let directoriesWithDatFiles = 0; async function traverseDirectory(directory: string): Promise<boolean> { directoriesChecked++; let datFileFound = false; try { const directoryContents = await fs.readdir(directory, { withFileTypes: true, }); for (const dirent of directoryContents) { const fullPath = path.join(directory, dirent.name); if (dirent.isDirectory()) { const isEmpty = await traverseDirectory(fullPath); if (isEmpty) { emptyDatDirectories.push(fullPath); } } else if (dirent.name.endsWith(\".dat\")) { datFileFound = true; try { const data = await fs.readFile(fullPath, \"utf8\"); const size = parseMapSize(data); if (size !== null) { totalSize += size; fileCount++; if (size < minSize) minSize = size; if (size > maxSize) maxSize = size; } else { failedCount++; failedFiles.push(fullPath); } } catch (readError) { console.error( `[ERROR] Error reading file ${fullPath}: ${readError}` ); failedCount++; failedFiles.push(fullPath); } } } } catch (dirError) { console.error( `[ERROR] Error accessing directory ${directory}: ${dirError}` ); } if (datFileFound) { directoriesWithDatFiles++; } return !datFileFound; } function parseMapSize(fileContent: string): number | null { const rowMatch = fileContent.match(/rowcount:\\s*(\\d+)/); const colMatch = fileContent.match(/colcount:\\s*(\\d+)/); if (rowMatch && colMatch) { return parseInt(rowMatch[1], 10) * parseInt(colMatch[1], 10); } return null; } const isEmpty = await traverseDirectory(baseDir); if (isEmpty) { emptyDatDirectories.push(baseDir); } const averageSize = fileCount > 0 ? (totalSize / fileCount).toFixed(2) : 0; const result = { processedFiles: fileCount, failedFiles: failedCount, directoriesChecked, directoriesWithDatFiles, averageSize, minSize, maxSize, failedFilesDetails: failedFiles, emptyDatDirectories, }; console.log(\"========== Manic Miners Map Tool Statistics ==========\"); console.log(`Processed files: ${fileCount}`); console.log(`Failed to process files: ${failedCount}`); console.log(`Directories checked: ${directoriesChecked}`); console.log(`Directories with .dat files: ${directoriesWithDatFiles}`); if (failedCount > 0) { console.log(\"Failed file paths:\"); failedFiles.forEach((file) => console.log(file)); } if (emptyDatDirectories.length > 0) { console.log(\"Directories without .dat files:\"); emptyDatDirectories.forEach((dir) => console.log(dir)); } console.log(`Average map size: ${averageSize}`); console.log(`Minimum map size: ${minSize}`); console.log(`Maximum map size: ${maxSize}`); console.log(\"======================================================\"); return result; } async function init() { try { const directoryPath = process.env.MMT_CATALOG_DIR || path.join(os.homedir(), \"Desktop\", \"discordChannelBot\", \"catalog\"); rl.question( `The directory to be processed is: ${directoryPath}. Would you like to proceed? (yes/no): \\n`, async (answer) => { if (answer.toLowerCase() === \"yes\") { const processingResults = await calculateMapSizeStats(directoryPath); console.log(processingResults); } else { console.log(\"[INFO] Process aborted by user.\"); } rl.close(); } ); } catch (err) { console.error( \"[ERROR] Error initializing map size stats calculation:\", err ); } } init();"},"cleanMapFile.ts":{"content":"import * as fs from \"fs\"; import * as path from \"path\"; import * as chardet from \"chardet\"; import * as iconv from \"iconv-lite\"; import * as os from \"os\"; import * as dotenv from \"dotenv\"; import * as readline from \"readline\"; dotenv.config(); const rl = readline.createInterface({ input: process.stdin, output: process.stdout, }); const cleanMapFile = (filePath: string): void => { const encoding = chardet.detectFileSync(filePath) || \"utf8\"; console.log(`Detected file encoding: ${encoding}`); fs.readFile(filePath, (err, data) => { if (err) { console.error(`[ERROR] Error reading file ${filePath}:`, err); return; } const fileContent = iconv.decode(data, encoding as BufferEncoding); const cleanFileContent = (content: string): string => { const printableContent = content.replace(/[^\\x20-\\x7E\\n\\r]/g, \"\"); return printableContent.replace(/\\r\\n/g, \"\\n\").replace(/\\r/g, \"\\n\"); }; const cleanedData = cleanFileContent(fileContent); const backupFilePath = `${filePath}.bak`; fs.rename(filePath, backupFilePath, (renameErr) => { if (renameErr) { console.error( `[ERROR] Error renaming file ${filePath} to ${backupFilePath}:`, renameErr ); return; } fs.writeFile(filePath, iconv.encode(cleanedData, \"utf8\"), (writeErr) => { if (writeErr) { console.error( `[ERROR] Error writing cleaned content to ${filePath}:`, writeErr ); return; } console.log( `[INFO] Cleaned file content saved to ${filePath} for inspection.` ); const extractTilesArray = (content: string): number[] | null => { try { const tilesMatch = content.match(/tiles\\s*\\{\\s*([^}]*)\\s*\\}/); if (tilesMatch) { const tilesString = tilesMatch[1]; const tilesArray = tilesString .split(/[\\s,]+/) .map((num) => num.trim()) .filter((num) => num.length > 0 && num !== \"-\") .map((num) => parseInt(num, 10)) .filter((num) => !isNaN(num)); return tilesArray; } return null; } catch (error) { console.error(`[ERROR] Error extracting tiles array:`, error); return null; } }; const tilesArray = extractTilesArray(cleanedData); if (tilesArray) { console.log( `[INFO] Successfully extracted and parsed tiles from ${filePath}` ); } else { console.log(`[FAIL] Failed to extract tiles from file: ${filePath}`); } }); }); }); }; const getDatFiles = (dirPath: string): Promise<string[]> => { return new Promise((resolve, reject) => { fs.readdir(dirPath, (err, files) => { if (err) { return reject(`[ERROR] Error reading directory ${dirPath}: ${err}`); } const datFiles = files.filter((file) => { const filePath = path.join(dirPath, file); return ( fs.statSync(filePath).isFile() && path.extname(filePath) === \".dat\" ); }); resolve(datFiles.map((file) => path.join(dirPath, file))); }); }); }; const processDatFiles = (filePaths: string[]): void => { filePaths.forEach(cleanMapFile); }; async function init() { try { const directoryPath = process.env.MMT_CLEANME_DIR || path.join(os.homedir(), \"Desktop\", \"discordChannelBot\", \"cleanme\"); const datFiles = await getDatFiles(directoryPath); if (datFiles.length === 0) { console.log(\"[INFO] No .dat files found to process.\"); rl.close(); return; } console.log(`\\nFiles to be processed:\\n${datFiles.join(\"\\n\")}\\n`); rl.question( `There are ${datFiles.length} files to process. Would you like to proceed? (yes/no): \\n`, (answer) => { if (answer.toLowerCase() === \"yes\") { processDatFiles(datFiles); } else { console.log(\"[INFO] Process aborted by user.\"); } rl.close(); } ); } catch (err) { console.error(\"[ERROR] Error initializing clean map files:\", err); } } init();"},"generatePNG.ts":{"content":"require(\"dotenv\").config(); const fs = require(\"fs\").promises; import path from \"path\"; import { generatePNG } from \"../src/functions/generatePNG\"; import { create2DArray } from \"../src/functions/create2DArray\"; import { parseMapDataFromFile } from \"../fileParser/mapFileParser\"; export async function generatePNGFromFiles( filePaths: string[] | string ): Promise<{ success: boolean }[]> { const files = Array.isArray(filePaths) ? filePaths : [filePaths]; const results = []; for (const filePath of files) { const outputFilePath = filePath.replace(/\\.dat$/, \".png\"); try { const parsedData = await parseMapDataFromFile({ filePath }); const wallArray = create2DArray({ data: parsedData.tilesArray, width: parsedData.colcount, }); const image = await generatePNG(wallArray, parsedData.biome); await image.toFile(outputFilePath); console.log(\"Image padded with border and saved as \" + outputFilePath); results.push({ success: true, filePath: outputFilePath }); } catch (error) { console.error(\"Error processing file:\", filePath, error); results.push({ success: false, filePath: outputFilePath }); } } return results; } // Helper function to find all dat files recursively in a directory async function findAllDatFiles(dir: any) { let results: any[] = []; const entries = await fs.readdir(dir, { withFileTypes: true }); for (const entry of entries) { const fullPath = path.join(dir, entry.name); if (entry.isDirectory()) { results = results.concat(await findAllDatFiles(fullPath)); // Recursively find in subdirectories } else if (entry.isFile() && entry.name.endsWith(\".dat\")) { results.push(fullPath); // Collect dat files } } return results; } // Function to process all dat files in a directory and its subdirectories export async function processDirectory(datDirectory: string) { const datFiles = await findAllDatFiles(datDirectory); const results = []; for (const filePath of datFiles) { const outputFilePath = filePath.replace(/\\.dat$/, \".png\"); try { const parsedData = await parseMapDataFromFile({ filePath }); const wallArray = create2DArray({ data: parsedData.tilesArray, width: parsedData.colcount, }); // console.log(parsedData); const image = await generatePNG(wallArray, parsedData.biome); await image.toFile(outputFilePath); console.log(\"Image padded with border and saved as \" + outputFilePath); results.push({ success: true, filePath: outputFilePath }); } catch (error) { console.error(\"Error processing file:\", filePath, error); results.push({ success: false, filePath: outputFilePath }); } } return results; } // Generate PNGs for all .dat levels in the directory async function init() { const directoryPath = process.env.MMT_CATALOG_DIR; const processingResults = await processDirectory(directoryPath); console.log(processingResults); } init();"},"logMapDataStats.ts":{"content":"import * as os from \"os\"; import * as fs from \"fs/promises\"; import * as path from \"path\"; import * as dotenv from \"dotenv\"; import * as readline from \"readline\"; import { ParsedMapData } from \"../fileParser/types\"; import { parseMapDataFromFile } from \"../fileParser/mapFileParser\"; dotenv.config(); const rl = readline.createInterface({ input: process.stdin, output: process.stdout, }); async function logMapDataStats(baseDir: string): Promise<any> { let fileCount = 0; let failedCount = 0; const failedFiles: string[] = []; const mapDataResults: ParsedMapData[] = []; async function traverseDirectory(directory: string): Promise<void> { try { const directoryContents = await fs.readdir(directory, { withFileTypes: true, }); for (const dirent of directoryContents) { const fullPath = path.join(directory, dirent.name); if (dirent.isDirectory()) { await traverseDirectory(fullPath); } else if (dirent.name.endsWith(\".dat\")) { fileCount++; try { const mapData = await parseMapDataFromFile({ filePath: fullPath }); mapDataResults.push(mapData); } catch (parseError) { console.error( `[ERROR] Failed to parse file ${fullPath}: ${parseError}` ); failedCount++; failedFiles.push(fullPath); } } } } catch (dirError) { console.error( `[ERROR] Error accessing directory ${directory}: ${dirError}` ); } } await traverseDirectory(baseDir); const result = { processedFiles: fileCount, failedFiles: failedCount, mapDataResults, failedFilesDetails: failedFiles, }; console.log(\"========== Map Data Parsing Results ==========\"); console.log(`Processed files: ${fileCount}`); console.log(`Failed to process files: ${failedCount}`); if (failedCount > 0) { console.log(\"Failed file paths:\"); failedFiles.forEach((file) => console.log(file)); } console.log(\"Parsed Map Data:\"); mapDataResults.forEach((data, index) => { console.log(`Map ${index + 1}:`, JSON.stringify(data, null, 2)); }); console.log(\"=================================================\"); return result; } async function init() { try { const directoryPath = process.env.MMT_MAPDATA_DIR || path.join(os.homedir(), \"Desktop\", \"discordChannelBot\", \"downloads\"); rl.question( `The directory to be processed is: ${directoryPath}. Would you like to proceed? (yes/no): \\n`, async (answer) => { if (answer.toLowerCase() === \"yes\") { const processingResults = await logMapDataStats(directoryPath); console.log(processingResults); } else { console.log(\"[INFO] Process aborted by user.\"); } rl.close(); } ); } catch (err) { console.error(\"[ERROR] Error initializing map data parsing:\", err); } } init();"},"mapIntegrityCheck.ts":{"content":"import * as dotenv from \"dotenv\"; import * as fs from \"fs/promises\"; import * as path from \"path\"; import * as os from \"os\"; import * as chardet from \"chardet\"; import { Stats } from \"fs\"; import { colors } from \"../src/functions/colorMap\"; dotenv.config(); async function mapTileIntegrityCheck(baseDir: string): Promise<any> { const allTiles = new Set<number>(); const tileOccurrences: { [key: number]: number } = {}; const mapTileSets: Set<number>[] = []; let fileCount = 0; let failedCount = 0; let directoriesChecked = 0; let directoriesWithDatFiles = 0; const failedFiles: { path: string; size: number; metadata: Stats; encoding: string; }[] = []; async function traverseDirectory(directory: string): Promise<void> { directoriesChecked++; let datFileFound = false; try { const directoryContents = await fs.readdir(directory, { withFileTypes: true, }); for (const dirent of directoryContents) { const fullPath = path.join(directory, dirent.name); if (dirent.isDirectory()) { await traverseDirectory(fullPath); } else if (dirent.name.endsWith(\".dat\")) { datFileFound = true; try { const encoding = chardet.detectFileSync(fullPath) || \"utf8\"; const data = await fs.readFile(fullPath, \"utf8\"); const normalizedData = data .replace(/\\r\\n/g, \"\\n\") .replace(/\\r/g, \"\\n\"); const tilesArray = extractTilesArray(normalizedData); if (tilesArray) { const tileSet = new Set(tilesArray); mapTileSets.push(tileSet); tilesArray.forEach((tile) => { allTiles.add(tile); tileOccurrences[tile] = (tileOccurrences[tile] || 0) + 1; }); fileCount++; } else { console.log( `[FAIL] Failed to extract tiles from file: ${fullPath}` ); const stats = await fs.stat(fullPath); failedFiles.push({ path: fullPath, size: stats.size, metadata: stats, encoding, }); failedCount++; } } catch (readError) { console.error( `[ERROR] Error reading file ${fullPath}: ${readError}` ); const stats = await fs.stat(fullPath); const encoding = chardet.detectFileSync(fullPath) || \"utf8\"; failedFiles.push({ path: fullPath, size: stats.size, metadata: stats, encoding, }); failedCount++; } } } } catch (dirError) { console.error( `[ERROR] Error accessing directory ${directory}: ${dirError}` ); } if (datFileFound) { directoriesWithDatFiles++; } } function extractTilesArray(fileContent: string): number[] | null { try { const tilesMatch = fileContent.match(/tiles\\s*\\{\\s*([^}]*)\\s*\\}/); if (tilesMatch) { const tilesString = tilesMatch[1]; const tilesArray = tilesString .split(/[\\s,]+/) .map((num) => num.trim()) .filter((num) => num.length > 0 && num !== \"-\") // Filter out empty and invalid entries .map((num) => parseInt(num, 10)) .filter((num) => !isNaN(num)); return tilesArray; } return null; } catch (error) { console.error( `[ERROR] Error extracting tiles array from content:`, error ); return null; } } await traverseDirectory(baseDir); let commonTiles = new Set<number>([...allTiles]); mapTileSets.forEach((tileSet) => { commonTiles = new Set([...commonTiles].filter((tile) => tileSet.has(tile))); }); const standoutTiles = [...allTiles].filter( (tile) => !colors.hasOwnProperty(tile) ); const uniqueTiles = Object.keys(tileOccurrences) .map(Number) .filter((tile) => tileOccurrences[tile] === 1); const result = { processedFiles: fileCount, failedFiles: failedCount, directoriesChecked, directoriesWithDatFiles, totalUniqueTiles: allTiles.size, commonTiles: [...commonTiles], standoutTiles, uniqueTiles, failedFilesDetails: failedFiles, }; console.log(\"========== Map Integrity Check Summary ==========\"); console.log(`Processed files: ${fileCount}`); console.log(`Failed to process files: ${failedCount}`); console.log(`Directories checked: ${directoriesChecked}`); console.log(`Directories with .dat files: ${directoriesWithDatFiles}`); console.log( `Standout tiles (not matching colormap): ${standoutTiles.join(\", \")}` ); console.log( `Tiles that appeared in only one file: ${uniqueTiles.join( \", \" )}, consider adding them to the colormap` ); if (failedFiles.length > 0) { console.log(\"========== Failed Files ==========\"); failedFiles.forEach((file) => { console.log(\"----------------------------------\"); console.log(`File: ${file.path}`); console.log(`Size: ${file.size} bytes`); console.log(`Encoding: ${file.encoding}`); console.log(`Metadata:`, file.metadata); }); console.log(\"==================================\"); } return result; } async function init() { const directoryPath = process.env.MMT_CATALOG_DIR || path.join(os.homedir(), \"Desktop\", \"discordChannelBot\", \"catalog\"); const processingResults = await mapTileIntegrityCheck(directoryPath); console.log(processingResults); } init().catch((err) => console.error(\"[ERROR] Error initializing map tile integrity check:\", err) );"},"minifyProject.ts":{"content":"import * as fs from \"fs/promises\"; import * as path from \"path\"; import * as dotenv from \"dotenv\"; dotenv.config(); async function minifyDirectory( baseDir: string, ignoreList: string[] = [] ): Promise<any> { let directoryStructure: any = {}; async function traverseDirectory( currentPath: string, structure: any ): Promise<void> { const directoryContents = await fs.readdir(currentPath, { withFileTypes: true, }); for (const dirent of directoryContents) { if (ignoreList.includes(dirent.name)) continue; const fullPath = path.join(currentPath, dirent.name); if (dirent.isDirectory()) { console.log(`Directory: ${fullPath}`); structure[dirent.name] = {}; await traverseDirectory(fullPath, structure[dirent.name]); } else { console.log(`File: ${fullPath}`); const fileContent = await fs.readFile(fullPath, \"utf8\"); const minifiedContent = fileContent.replace(/\\s+/g, \" \").trim(); structure[dirent.name] = { content: minifiedContent, }; } } } await traverseDirectory(baseDir, directoryStructure); return directoryStructure; } async function init() { try { const baseDir = process.cwd(); const outputDir = process.env.MMT_OUTPUT_DIR || baseDir; const ignoreList = [ \"dist\", \"assets\", \"node_modules\", \".git\", \".vscode\", \"README.md\", \"package-lock.json\", ]; const outputFilePath = path.join(outputDir, \"directory_structure.json\"); // Wipe the output file if it exists try { await fs.unlink(outputFilePath); console.log(`[INFO] Existing output file '${outputFilePath}' deleted.`); } catch (err) { if (err.code !== \"ENOENT\") { console.error(\"[ERROR] Error deleting existing output file:\", err); } } const result = await minifyDirectory(baseDir, ignoreList); console.log(\"========== Directory Structure ==========\"); console.log(JSON.stringify(result, null, 2)); console.log(\"=========================================\"); await fs.writeFile(outputFilePath, JSON.stringify(result)); console.log( \"[INFO] Directory structure has been written to directory_structure.json\" ); } catch (err) { console.error(\"[ERROR] Error minifying directory:\", err); } } init();"}},"src":{"functions":{"colorMap.ts":{"content":"import { Color } from \"../types/types\"; export const colors: { [key: number | string]: Color | any } = { 1: { r: 124, g: 92, b: 70 }, // Ground 5: { r: 92, g: 58, b: 40 }, // not sure maybe hot rock almost lava 6: { r: 255, g: 50, b: 0 }, // Lava 11: { r: 30, g: 84, b: 197 }, // Water (Teal Blue) 12: { r: 180, g: 180, b: 20 }, // Slimy Slug hole 14: { r: 220, g: 220, b: 220 }, // Building power path 26: { r: 169, g: 109, b: 82 }, // Dirt 30: { r: 139, g: 104, b: 86 }, // Loose Rock 34: { r: 77, g: 53, b: 50 }, // Hard Rock 38: { r: 0, g: 0, b: 0, a: 0 }, // Solid Rock, fully transparent 42: { r: 206, g: 233, b: 104 }, // Energy Crystal Seam 46: { r: 200, g: 85, b: 30 }, // Ore Seam 50: { r: 255, g: 255, b: 70 }, // Recharge Seam 60: { r: 46, g: 23, b: 95, alpha: 0.1 }, // Landslide rubble 61: { r: 46, g: 23, b: 95, alpha: 0.5 }, // Landslide rubble 63: { r: 46, g: 23, b: 95 }, // Landslide rubble 101: { r: 124, g: 92, b: 70 }, // Ground 106: { r: 255, g: 70, b: 10, alpha: 0.9 }, // Lava 111: { r: 30, g: 95, b: 220 }, // Water 112: { r: 180, g: 180, b: 20 }, // Slimy Slug hole 114: { r: 220, g: 220, b: 220 }, // Building power path 115: { r: 220, g: 220, b: 220 }, //dunno 163: { r: 46, g: 23, b: 95 }, // Landslide rubble 164: { r: 65, g: 33, b: 95 }, // Landslide rubble 165: { r: 46, g: 23, b: 95, alpha: 0.5 }, // Weird Rubble? 124: { r: 70, g: 130, b: 180, alpha: 0.9 }, //Floating Flat Panels? rock: { r: 120, g: 115, b: 110, alpha: 0.3 }, // BIOME BORDER COLOR Rocky, natural grey with transparency lava: { r: 255, g: 50, b: 0, alpha: 0.3 }, // BIOME BORDER COLOR Lava, orange with transparency ice: { r: 150, g: 200, b: 240, alpha: 0.4 }, // BIOME BORDER COLOR Ice, lighter cyan with transparency };"},"create2DArray.ts":{"content":"/** * Creates a 2D array from a flat array of numbers by grouping elements into subarrays. * Each subarray will contain a specified number of elements, corresponding to the 'width' parameter. * * @param {number[]} data - The flat array of numbers to be converted into a 2D array. * @param {number} width - The number of elements each subarray should contain, representing the width of the 2D array. * @returns {number[][]} A 2D array where each subarray represents a row in the grid. */ export function create2DArray({ data, width, }: { data: number[]; width: number; }): number[][] { let result: number[][] = []; // Initialize the resulting 2D array // Iterate through the flat array in steps of 'width' to create subarrays for (let i = 0; i < data.length; i += width) { // Slice the flat array from the current index up to 'width' elements and add to the result result.push(data.slice(i, i + width)); } return result; // Return the newly created 2D array }"},"drawMapTiles.ts":{"content":"import { colors } from \"./colorMap\"; import { drawTile } from \"./drawTile\"; import { CanvasRenderingContext2D } from \"canvas\"; export async function drawMapTiles( ctx: CanvasRenderingContext2D, wallArray: string | any[], scale: number ) { for (let y = 0; y < wallArray.length; y++) { for (let x = 0; x < wallArray[0].length; x++) { const tile = wallArray[y][x]; const color = colors[tile] || { r: 255, g: 255, b: 255, a: 1 }; drawTile(ctx, x, y, scale, color); } } }"},"drawTile.ts":{"content":"import { Color } from \"../types/types\"; import { CanvasRenderingContext2D, createCanvas } from \"canvas\"; export function drawTile( ctx: CanvasRenderingContext2D, i: number, j: number, scale: number, color: Color ) { // Create a pattern canvas for detailed texture drawing const patternCanvas = createCanvas(scale, scale); const patternCtx = patternCanvas.getContext(\"2d\"); // Define a gradient for visual depth const tileGradient = patternCtx.createLinearGradient(0, 0, scale, scale); tileGradient.addColorStop( 0, `rgba(${color.r}, ${color.g}, ${color.b}, ${color.a || 1})` ); tileGradient.addColorStop( 1, `rgba(${Math.max(0, color.r - 20)}, ${Math.max( 0, color.g - 20 )}, ${Math.max(0, color.b - 20)}, ${color.a || 1})` ); patternCtx.fillStyle = tileGradient; patternCtx.fillRect(0, 0, scale, scale); // Add a subtle texture to the tile patternCtx.strokeStyle = \"rgba(255, 255, 255, 0.3)\"; patternCtx.lineWidth = 1; for (let k = 0; k < scale; k += 5) { patternCtx.beginPath(); patternCtx.moveTo(k, 0); patternCtx.lineTo(0, k); patternCtx.moveTo(scale, k); patternCtx.lineTo(k, scale); patternCtx.moveTo(k, scale); patternCtx.lineTo(scale, k); patternCtx.stroke(); } // Shadow and highlight for depth // Apply shadows for a raised tile effect ctx.shadowColor = \"rgba(0, 0, 0, 0.5)\"; ctx.shadowBlur = 5; ctx.shadowOffsetX = 3; ctx.shadowOffsetY = 3; // Apply the pattern const pattern = ctx.createPattern(patternCanvas, \"repeat\"); ctx.fillStyle = pattern; ctx.fillRect(j * scale, i * scale, scale, scale); // Draw highlight on the top and left edges for a beveled look ctx.strokeStyle = \"rgba(255, 255, 255, 0.8)\"; ctx.beginPath(); ctx.moveTo(j * scale, i * scale + scale); ctx.lineTo(j * scale, i * scale); ctx.lineTo(j * scale + scale, i * scale); ctx.stroke(); // Reset shadow to prevent it from affecting other elements ctx.shadowColor = \"transparent\"; ctx.shadowBlur = 0; ctx.shadowOffsetX = 0; ctx.shadowOffsetY = 0; }"},"generatePNG.ts":{"content":"import sharp from \"sharp\"; import { colors } from \"./colorMap\"; import { createCanvas } from \"canvas\"; import { drawMapTiles } from \"./drawMapTiles\"; async function processImage( buffer: sharp.SharpOptions | Buffer | any, height: number, width: number, scale: number, frameSize: number, padding: number, biome: string ) { let image = sharp(buffer).sharpen(); if (height * scale > width * scale) { image = image.rotate(90); } image = await image.resize(frameSize - 2 * padding, frameSize - padding, { fit: \"inside\", withoutEnlargement: true, }); return image.extend({ top: padding, bottom: padding, left: padding, right: padding, background: colors[biome.toLowerCase()] || { r: 0, g: 0, b: 0, alpha: 0.31, }, }); } export async function generatePNG( wallArray: number[][], biome = \"default\" ): Promise<sharp.Sharp> { const scale = 30; const height = wallArray.length; const width = wallArray[0].length; const canvas = createCanvas(width * scale, height * scale); const ctx = canvas.getContext(\"2d\"); await drawMapTiles(ctx, wallArray, scale); const buffer = canvas.toBuffer(\"image/png\"); const frameSize = 1024; const padding = 50; const image = await processImage( buffer, height, width, scale, frameSize, padding, biome ); const finalCanvas = await image.toBuffer(); return sharp(finalCanvas); }"}},"types":{"types.ts":{"content":"export interface Color { r: number; g: number; b: number; a?: number; }"}}},"tsconfig.json":{"content":"{ \"compilerOptions\": { \"module\": \"commonjs\", \"esModuleInterop\": true, \"target\": \"es6\", \"noImplicitAny\": true, \"moduleResolution\": \"node\", \"sourceMap\": true, \"outDir\": \"dist\", \"baseUrl\": \".\", \"paths\": { \"*\": [\"node_modules/*\"] } }, \"include\": [\"*.ts\", \"*.js\", \"src/**/*.ts\", \"scripts/*.ts\", \"scripts/*.js\"] }"}}